1.数据结构
  String：
    SDS（simple dynamic string，简单动态字符串）
    struct sdshdr{
       //记录buf数组中已使用字节的数量
       //等于 SDS 保存字符串的长度
       int len;
       //记录 buf 数组中未使用字节的数量
       int free;
       //字节数组，用于保存字符串
       char buf[];
    }
    相较于c语言的string，判断长度时直接读取len属性就行。而且c的string必须以‘\0’结尾，一旦识别到‘\0’就当成字符串结束。
    c语言的字符串修改的时候需要手动分配内存，如果没有分配，增长时可能造成缓冲区溢出，减小时可能造成内存泄漏。
    而sds有len和free两个属性，对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略：
    a.空间预分配：每次扩展的时候扩展的会比实际的多，减少连续扩展导致的内存频繁分配。
    b.惰性空间释放：每次缩短的时候不会立马回收内存，而是使用free属性将这些字节的数量记录下来，等待后续使用。
  List：
    双向链表或者压缩列表（当一个列表键（list）只包含少量的列表项，并且每个列表项都是小整数值，或者长度比较短的字符串，那么 Redis 就会使用压缩列表作为列表键（list）的底层实现）
    压缩列表：
      typedf struct ziplist<T>{
          //压缩列表占用字符数
          int32 zlbytes;
          //最后一个元素距离起始位置的偏移量，用于快速定位最后一个节点
          int32 zltail_offset;
          //元素个数
          int16 zllength;
          //元素内容
          T[] entries;
          //结束位 0xFF
          int8 zlend;
      }ziplist
      
      typede struct entry{
          //前一个entry的长度
          int<var> prelen;
          //元素类型编码
          int<var> encoding;
          //元素内容
          optional byte[] content;
      }entry
    prelen会根据前一个entry的长度来分配大小：
      前一个节点的长度小于254个字节，则prelen长度为1字节；
      前一个节点的长度大于254字节，则prelen长度为5字节；
      所以存在一种多米诺骨牌的现象：
        当每个结点长度都是250~254之间时，每个prelen的长度都是1，如果第一个结点长度修改成大于254，那么后面每一个结点的prelen都会修改，造成多米诺骨牌的现象。
    linkedList与zipList的对比：
      双向链表linkedList便于在表的两端进行push和pop操作，在插入节点上复杂度很低，但是它的内存开销比较大。
      首先，它在每个节点上除了要保存数据之外，还有额外保存两个指针；其次，双向链表的各个节点都是单独的内存块，地址不连续，容易形成内存碎片。
      zipList存储在一块连续的内存上，所以存储效率很高。
      但是它不利于修改操作，插入和删除操作需要频繁地申请和释放内存。特别是当zipList长度很长时，一次realloc可能会导致大量的数据拷贝。
    新增的quickList：
      LinkList包zipList
  Hash：
    类似于java的hash，采用链式哈希来解决冲突。
    同理于list，在数据量较少的时候也会使用ziplist来保存。
    注意rehash方法：
      redis的hash内部维护了两个哈希数组「哈希表 1」和「哈希表 2 」 
      在正常服务请求阶段，插入的数据，都会写入到「哈希表 1」，此时的「哈希表 2 」 并没有被分配空间。
      当发生rehash时：
        a.给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍；
        b.将「哈希表 1 」的数据迁移到「哈希表 2」 中；
        c.迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备。
    其中有个问题：
      在第二步数据迁移的时候，会有大量拷贝工作，可能会对redis造成阻塞。
    渐进式rehash：
      a.给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍；
      b.在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上；
      c.随着处理客户端发起的哈希表操作请求数量越多，最终会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。
    rehash条件：
      根据负载因子来判断：
        负载因子 = 哈希表已保存的结点数量 / 哈希表大小；
      当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。
      当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。  
      
      
      
